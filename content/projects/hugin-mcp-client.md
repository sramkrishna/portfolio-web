+++
title = "Hugin MCP Client"
description = "A Python client that connects an LLM to a MCP server."
date = 2025-10-23T20:39:52-07:00
types = ["tech"]  # Options: "gnome", "tech", "events"
tags = ["LLM", "AI/ML","MCP", "GNOME"]

[[links]]
name = "Github Link"
url = "https://github.com/sramkrishna/hugin-mcp-client"
external = true
+++

## Project Overview

The MCP client is used as a way to test ratatoskr mcp server. Both
projects serve as a way to enable an AI PC idea to connect an LLM to
do useful tasks on a laptop or desktop. Hugin supports both a local LLM
and Claude. Optimizing the local LLM usecase will be priority.

### Key points

- Build a Linux based "AI PC" on the GNOME desktop
- Use the MCP client as a way to test the MCP server to try doing tooling requests.
- Show the viabilty of doing AI on the Linux platform.

### Impact

- Show usefulness of an AI workflow on Linux
